{"cells":[{"cell_type":"code","execution_count":null,"id":"49a646f2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"49a646f2","executionInfo":{"status":"ok","timestamp":1757565962028,"user_tz":-540,"elapsed":21991,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}},"outputId":"d7e9fb67-055c-4d88-c814-812a0f74cf8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n","Collecting numpy<2 (from mediapipe)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.59.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n","INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n","Collecting opencv-contrib-python (from mediapipe)\n","  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n","Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n","Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: opencv-contrib-python\n","    Found existing installation: opencv-contrib-python 4.12.0.88\n","    Uninstalling opencv-contrib-python-4.12.0.88:\n","      Successfully uninstalled opencv-contrib-python-4.12.0.88\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]},"id":"b98ea123ba3447208263c30bcc5fdf76"}},"metadata":{}}],"source":["! pip install mediapipe\n"]},{"cell_type":"code","execution_count":2,"id":"c7f750ba","metadata":{"id":"c7f750ba","executionInfo":{"status":"ok","timestamp":1757568085965,"user_tz":-540,"elapsed":4288,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}}},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","\n","import time\n","import os\n","\n","mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils"]},{"cell_type":"code","execution_count":3,"id":"459d24af","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"459d24af","executionInfo":{"status":"ok","timestamp":1757568089414,"user_tz":-540,"elapsed":5,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}},"outputId":"e73476a9-4734-4cfd-ebde-92adc5c4e453"},"outputs":[{"output_type":"stream","name":"stdout","text":["['FaceDetection', 'FaceKeyPoint', 'NamedTuple', 'SolutionBase', 'Union', '_FULL_RANGE_GRAPH_FILE_PATH', '_SHORT_RANGE_GRAPH_FILE_PATH', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'detection_pb2', 'enum', 'face_detection_pb2', 'get_key_point', 'location_data_pb2', 'np']\n","['FACEMESH_CONTOURS', 'FACEMESH_FACE_OVAL', 'FACEMESH_IRISES', 'FACEMESH_LEFT_EYE', 'FACEMESH_LEFT_EYEBROW', 'FACEMESH_LEFT_IRIS', 'FACEMESH_LIPS', 'FACEMESH_NOSE', 'FACEMESH_NUM_LANDMARKS', 'FACEMESH_NUM_LANDMARKS_WITH_IRISES', 'FACEMESH_RIGHT_EYE', 'FACEMESH_RIGHT_EYEBROW', 'FACEMESH_RIGHT_IRIS', 'FACEMESH_TESSELATION', 'FaceMesh', 'NamedTuple', 'SolutionBase', '_BINARYPB_FILE_PATH', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'association_calculator_pb2', 'constant_side_packet_calculator_pb2', 'detections_to_rects_calculator_pb2', 'gate_calculator_pb2', 'image_to_tensor_calculator_pb2', 'inference_calculator_pb2', 'landmarks_refinement_calculator_pb2', 'logic_calculator_pb2', 'non_max_suppression_calculator_pb2', 'np', 'rect_transformation_calculator_pb2', 'split_vector_calculator_pb2', 'ssd_anchors_calculator_pb2', 'tensors_to_classification_calculator_pb2', 'tensors_to_detections_calculator_pb2', 'tensors_to_landmarks_calculator_pb2', 'thresholding_calculator_pb2']\n","['HAND_CONNECTIONS', 'HandLandmark', 'Hands', 'NamedTuple', 'SolutionBase', '_BINARYPB_FILE_PATH', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'association_calculator_pb2', 'constant_side_packet_calculator_pb2', 'detections_to_rects_calculator_pb2', 'enum', 'gate_calculator_pb2', 'image_to_tensor_calculator_pb2', 'inference_calculator_pb2', 'logic_calculator_pb2', 'non_max_suppression_calculator_pb2', 'np', 'rect_transformation_calculator_pb2', 'split_vector_calculator_pb2', 'ssd_anchors_calculator_pb2', 'tensors_to_classification_calculator_pb2', 'tensors_to_detections_calculator_pb2', 'tensors_to_landmarks_calculator_pb2', 'thresholding_calculator_pb2']\n"]}],"source":["from mediapipe import solutions as mp\n","# ì–¼êµ´\n","print(dir(mp.face_detection))\n","# ì–¼êµ´ ë§¤ì‰¬\n","print(dir(mp.face_mesh))\n","# ì†\n","print(dir(mp.hands))"]},{"cell_type":"code","execution_count":4,"id":"cd1512d9","metadata":{"id":"cd1512d9","executionInfo":{"status":"ok","timestamp":1757568090226,"user_tz":-540,"elapsed":6,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}}},"outputs":[],"source":["\n","# #Face Detection ëª¨ë¸ ì„¤ì •\n","# with mp_face_detection.FaceDetection(\n","#     model_selection=1, min_detection_confidence=0.5) as face_detection:\n","\n","#     #ì›¹ìº  ì—´ê¸°\n","#     cap = cv2.VideoCapture(0)\n","#     if not cap.isOpened():\n","#       print(\"ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","#       exit()\n","#     while cap.isOpened() :\n","#       success, frame = cap.read()\n","#       if not success :\n","#         print(\"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","#         continue\n","\n","#       #BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜\n","#       image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","#       #ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬\n","#       results = face_detection.process(image)\n","\n","#       if results.detections:\n","#         # ê°ì§€ëœ ëª¨ë“  ì–¼êµ´ì— ëŒ€í•´ ë°˜ë³µ\n","#         for detection in results.detections:\n","#           mp_drawing.draw_detection(frame, detection)\n","\n","#         # í™”ë©´ì— ê²°ê³¼ í‘œì‹œ\n","#         cv2.imshow('Face Detection', frame)\n","\n","#         #'q'ëˆ„ë¥´ë©´ ì¢…ë£Œ\n","#         key = cv2.waitKey(30) & 0xFF\n","#         if key == ord('q'):\n","#           break\n","#         elif key == ord('c'):\n","#           timestamp = int(time.time())\n","#           filename = f\"capture_{timestamp}.png\"\n","#           cv2.imwrite(filename, frame)\n","#           print(f\"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filename}\")\n","\n","#     cap.release()\n","#     cv2.destroyAllWindows()\n","\n","\n"]},{"cell_type":"code","execution_count":5,"id":"7385f183","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"id":"7385f183","executionInfo":{"status":"error","timestamp":1757568090613,"user_tz":-540,"elapsed":25,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}},"outputId":"4f9fdfdb-aea3-478e-c8b5-43fad4d6c22e"},"outputs":[{"output_type":"stream","name":"stdout","text":["âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'isOpened'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-968830629.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     model_selection=0, min_detection_confidence=0.5) as face_detection:\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'isOpened'"]}],"source":["# ì €ì¥ í´ë” ìƒì„±\n","save_dir = \"captures\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# ì•ˆì „í•œ ì›¹ìº  ì—´ê¸°\n","cap = None\n","for i in range(3):  # 0, 1, 2ë²ˆ ì¹´ë©”ë¼ ì‹œë„\n","    cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)  # DirectShow ë°±ì—”ë“œ ì‚¬ìš©\n","    if cap.isOpened():\n","        ret, test_frame = cap.read()\n","        if ret and test_frame is not None:\n","            print(f\"ì›¹ìº  {i} ì—°ê²° ì„±ê³µ!\")\n","            break\n","        else:\n","            cap.release()\n","            cap = None\n","    else:\n","        cap = None\n","\n","if cap is None:\n","    print(\"âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n","    exit()\n","\n","# FaceDetection ì´ˆê¸°í™”\n","with mp_face_detection.FaceDetection(\n","    model_selection=0, min_detection_confidence=0.5) as face_detection:\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","            continue\n","\n","        # BGR -> RGB\n","        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","        # ì–¼êµ´ ê°ì§€\n","        results = face_detection.process(image_rgb)\n","\n","        # ì–¼êµ´ ê·¸ë¦¬ê¸°\n","        if results.detections:\n","            for detection in results.detections:\n","                mp_drawing.draw_detection(frame, detection)\n","\n","        # í™”ë©´ ì¶œë ¥\n","        cv2.imshow('Face Detection', frame)\n","\n","        # í‚¤ ì…ë ¥ ì²˜ë¦¬\n","        key = cv2.waitKey(30) & 0xFF\n","        if key == ord('q'):  # q ëˆ„ë¥´ë©´ ì¢…ë£Œ\n","            break\n","        elif key == ord('c'):  # c ëˆ„ë¥´ë©´ ìº¡ì²˜\n","            if results.detections:\n","                timestamp = int(time.time())\n","                h, w, _ = frame.shape\n","\n","                for i, detection in enumerate(results.detections):\n","                    #ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤ ê°€ì ¸ì˜¤ê¸°\n","                    bboxC = detection.location_data.relative_bounding_box\n","                    x_min = int(bboxC.xmin * w)\n","                    y_min = int(bboxC.ymin * h)\n","                    box_width = int(bboxC.width * w)\n","                    box_height = int(bboxC.height * h)\n","\n","                    # ì–¼êµ´ ì˜ì—­ë§Œ ì˜ë¼ë‚´ê¸°\n","                    face_crop = frame[\n","                        max(0, y_min):min(h, y_min + box_height),\n","                        max(0, x_min):min(w,x_min + box_width)\n","                    ]\n","\n","                    # íŒŒì¼ëª… ì§€ì •\n","                    filename = os.path.join(save_dir, f\"face_{timestamp}_{i}.png\")\n","                    cv2.imwrite(filename, face_crop)\n","                    print(f\"ğŸ“¸ ì–¼êµ´ {i} ì €ì¥ ì™„ë£Œ: {filename}\")\n","            else:\n","                print(\"ì €ì¥í•  ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.\")\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"82393b5a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"82393b5a","executionInfo":{"status":"error","timestamp":1757566153685,"user_tz":-540,"elapsed":63,"user":{"displayName":"Kim Jiyun","userId":"04469347296389469154"}},"outputId":"ecd21283-09cc-4396-b3a6-9f3b6dfe82ad"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1251724206.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ì €ì¥ í´ë” ìƒì„±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"captures\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# FaceDetection ì´ˆê¸°í™”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}],"source":["# ì €ì¥ í´ë” ìƒì„±\n","save_dir = \"captures\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# FaceDetection ì´ˆê¸°í™”\n","with mp_face_detection.FaceDetection(\n","    model_selection=0, min_detection_confidence=0.5) as face_detection:\n","\n","    cap = cv2.VideoCapture(0)\n","    if not cap.isOpened():\n","        print(\"ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        exit()\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","            continue\n","\n","        # BGR -> RGB ë³€í™˜\n","        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","        # ì–¼êµ´ ê°ì§€\n","        results = face_detection.process(image_rgb)\n","\n","        # ì–¼êµ´ ê·¸ë¦¬ê¸°\n","        if results.detections:\n","            h, w, _ = frame.shape\n","            for i, detection in enumerate(results.detections):\n","                bboxC = detection.location_data.relative_bounding_box\n","                x_min = int(bboxC.xmin * w)\n","                y_min = int(bboxC.ymin * h)\n","                box_width = int(bboxC.width * w)\n","                box_height = int(bboxC.height * h)\n","\n","                # ì¸ì‹ ì‹ ë¢°ë„(%)\n","                score = detection.score[0]\n","                confidence_text = f\"{int(score*100)}%\"\n","\n","                # ì–¼êµ´ ë²ˆí˜¸\n","                label = f\"Person{i+1} ({confidence_text})\"\n","\n","                #ì–¼êµ´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n","                cv2.rectangle(frame, (x_min, y_min),(x_min + box_width, y_min + box_height), (0,255,0),2)\n","\n","                # í…ìŠ¤íŠ¸ ì¶œë ¥\n","                cv2.putText(frame, label, (x_min, y_min - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0),2 )\n","\n","                # ì½” ë ì¢Œí‘œ êµ¬í•˜ê¸°\n","                keypoints = detection.location_data.relative_keypoints\n","                nose_tip = keypoints[2]\n","                nose_x = int(nose_tip.x * w)\n","                nose_y = int(nose_tip.y * h)\n","\n","                # ì½” ë ì°ê¸° (ë¹¨ê°„ ì )\n","                cv2. circle(frame, (nose_x, nose_y), 5, (0,0,255), -1)\n","\n","                # ì½” ë ì¢Œí‘œ í…ìŠ¤íŠ¸\n","                cv2.putText(frame, f\"Nose ({nose_x},{nose_y})\",\n","                            (nose_x + 10, nose_y),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n","\n","        # í™”ë©´ ì¶œë ¥\n","        cv2.imshow('Face Detection', frame)\n","\n","        # í‚¤ ì…ë ¥ ì²˜ë¦¬\n","        key = cv2.waitKey(30) & 0xFF\n","        if key == ord('q'):  # q ëˆ„ë¥´ë©´ ì¢…ë£Œ\n","            break\n","        elif key == ord('c'):  # c ëˆ„ë¥´ë©´ ìº¡ì²˜\n","            timestamp = int(time.time())\n","\n","            # ì›ë³¸ í”„ë ˆì„ ì €ì¥\n","            frame_filename = os.path.join(save_dir, f\"frame_{timestamp}.png\")\n","            cv2.imwrite(frame_filename, frame)\n","            print(f\"ì›ë³¸ í”„ë ˆì„ ì €ì¥ ì™„ë£Œ: {frame_filename}\")\n","\n","            # ì–¼êµ´ í¬ë¡­ ì €ì¥\n","            if results.detections:\n","                for i, detection in enumerate(results.detections):\n","                    bboxC = detection.location_data.relative_bounding_box\n","                    x_min = int(bboxC.xmin * w)\n","                    y_min = int(bboxC.ymin * h)\n","                    box_width = int(bboxC.width * w)\n","                    box_height = int(bboxC.height * h)\n","\n","                    face_crop = frame[\n","                        max(0, y_min):min(h, y_min + box_height),\n","                        max(0, x_min):min(w, x_min + box_width)\n","                    ]\n","\n","                    face_filename = os.path.join(save_dir, f\"face_{timestamp}_{i}.png\")\n","                    cv2.imwrite(face_filename, face_crop)\n","                    print(f\"   ì–¼êµ´ {i} ì €ì¥ ì™„ë£Œ: {face_filename}\")\n","            else:\n","                print(\"ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ì›ë³¸ í”„ë ˆì„ë§Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"361f40ac","metadata":{"id":"361f40ac","outputId":"f08a9a93-c68f-4a01-f837-a5248ea42932"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-10 16:04:17.518 python[2472:64920] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"]},{"name":"stdout","output_type":"stream","text":["\n","[results ê°ì²´ ì†ì„±]\n","['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_field_defaults', '_fields', '_make', '_replace', 'count', 'detections', 'index']\n","\n","[ì²« ë²ˆì§¸ detection ì†ì„±]\n","['AssociatedDetection', 'ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom', 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions', 'FindInitializationErrors', 'FromString', 'HasExtension', 'HasField', 'IsInitialized', 'ListFields', 'MergeFrom', 'MergeFromString', 'ParseFromString', 'RegisterExtension', 'SerializePartialToString', 'SerializeToString', 'SetInParent', 'UnknownFields', 'WhichOneof', '_CheckCalledFromGeneratedFile', '_SetListener', '__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__unicode__', 'associated_detections', 'detection_id', 'display_name', 'feature_tag', 'label', 'label_id', 'location_data', 'score', 'timestamp_usec', 'track_id']\n","\n","[score ê°’]\n","[0.8923986554145813]\n","\n","[location_data ì†ì„±]\n","['BOUNDING_BOX', 'BinaryMask', 'BoundingBox', 'ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom', 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions', 'FindInitializationErrors', 'Format', 'FromString', 'GLOBAL', 'HasExtension', 'HasField', 'IsInitialized', 'ListFields', 'MASK', 'MergeFrom', 'MergeFromString', 'ParseFromString', 'RELATIVE_BOUNDING_BOX', 'RegisterExtension', 'RelativeBoundingBox', 'RelativeKeypoint', 'SerializePartialToString', 'SerializeToString', 'SetInParent', 'UnknownFields', 'WhichOneof', '_CheckCalledFromGeneratedFile', '_SetListener', '__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__unicode__', 'bounding_box', 'format', 'mask', 'relative_bounding_box', 'relative_keypoints']\n"]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1757487859.451876   64920 gl_context.cc:369] GL version: 2.1 (2.1 ATI-7.0.23), renderer: AMD Radeon Pro 5500M OpenGL Engine\n","W0000 00:00:1757487859.455780   77447 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]}],"source":["import cv2\n","import mediapipe as mp\n","\n","mp_face_detection = mp.solutions.face_detection\n","\n","cap = cv2.VideoCapture(0)\n","ret, frame = cap.read()\n","cap.release()\n","\n","# BGR â†’ RGB\n","image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","with mp_face_detection.FaceDetection(\n","    model_selection=0, min_detection_confidence=0.5) as face_detection:\n","\n","    results = face_detection.process(image_rgb)\n","\n","    print(\"\\n[results ê°ì²´ ì†ì„±]\")\n","    print(dir(results))\n","\n","    if results.detections:\n","        detection = results.detections[0]\n","        print(\"\\n[ì²« ë²ˆì§¸ detection ì†ì„±]\")\n","        print(dir(detection))\n","\n","        print(\"\\n[score ê°’]\")\n","        print(detection.score)\n","\n","        print(\"\\n[location_data ì†ì„±]\")\n","        print(dir(detection.location_data))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"74a9a14a","metadata":{"id":"74a9a14a","outputId":"92600115-9ce4-4f08-cebd-8f189001f868"},"outputs":[{"ename":"NameError","evalue":"name 'results' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(results))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(results\u001b[38;5;241m.\u001b[39mdetections))\n\u001b[1;32m      3\u001b[0m help(mp_face_detection\u001b[38;5;241m.\u001b[39mFaceDetection)\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"]}],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}