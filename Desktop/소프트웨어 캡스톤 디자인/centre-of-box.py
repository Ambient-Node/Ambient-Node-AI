import cv2
import mediapipe as mp
import matplotlib.pyplot as plt
import time
import os
import numpy as np

mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils

# ì €ì¥ í´ë” ìƒì„±
save_dir = "captures"
os.makedirs(save_dir, exist_ok=True)

def enhance_image_for_detection(image):
    """ì–¼êµ´ ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    # 1. ë°ê¸° ë° ëŒ€ë¹„ ì¡°ì •
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    
    # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)
    
    # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)
    
    return enhanced

# FaceDetection ì´ˆê¸°í™” (ì¥ê±°ë¦¬ ëª¨ë¸ + ë‚®ì€ confidence)
with mp_face_detection.FaceDetection(
    model_selection=1,  # 0: ë‹¨ê±°ë¦¬(2m), 1: ì¥ê±°ë¦¬(5m) - ë©€ë¦¬ì„œë„ ì¸ì‹ ê°€ëŠ¥
    min_detection_confidence=0.3) as face_detection:  # confidence ë‚®ì¶¤ (0.5 â†’ 0.3)

    # **Fedora Linuxìš© ì¹´ë©”ë¼ ì´ˆê¸°í™”**
    cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
    if not cap.isOpened():
        print("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
        for i in range(1, 5):
            cap = cv2.VideoCapture(i, cv2.CAP_V4L2)
            if cap.isOpened():
                print(f"ì¹´ë©”ë¼ {i}ë²ˆìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
        else:
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            exit()

    # **ìµœì  í•´ìƒë„ ì„¤ì •**
    current_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    current_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"í˜„ì¬ ì¹´ë©”ë¼ í•´ìƒë„: {current_width}x{current_height}")
    
    # FHD í•´ìƒë„ ì„¤ì •
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    
    # **ì¹´ë©”ë¼ ì„¤ì • ìµœì í™” (ì–¼êµ´ ì¸ì‹ë¥  í–¥ìƒ)**
    cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # ìë™ ë…¸ì¶œ í™œì„±í™”
    cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)         # ìë™ í¬ì»¤ìŠ¤ í™œì„±í™”
    
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"ì„¤ì •ëœ ì¹´ë©”ë¼ í•´ìƒë„: {actual_width}x{actual_height}")
    print("ğŸ” ì¥ê±°ë¦¬ ì–¼êµ´ ì¸ì‹ ëª¨ë“œ (ìµœëŒ€ 5ë¯¸í„°)")
    
    # ì°½ ì„¤ì •
    window_name = 'Enhanced Face Detection - Long Range'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)
    
    scale_factor = 0.8
    window_width = int(actual_width * scale_factor)
    window_height = int(actual_height * scale_factor)
    cv2.resizeWindow(window_name, window_width, window_height)
    
    print(f"ì°½ í¬ê¸°: {window_width}x{window_height}")
    print("ì¡°ì‘ í‚¤:")
    print("  q: ì¢…ë£Œ")
    print("  c: ìº¡ì²˜")
    print("  +: ì°½ í¬ê¸° í™•ëŒ€")
    print("  -: ì°½ í¬ê¸° ì¶•ì†Œ")
    print("  r: ì°½ í¬ê¸° ë¦¬ì…‹")
    print("  f: ì „ì²´í™”ë©´ í† ê¸€")
    print("  e: ì´ë¯¸ì§€ í–¥ìƒ ON/OFF")

    current_scale = scale_factor
    enhancement_enabled = True  # ì´ë¯¸ì§€ í–¥ìƒ ê¸°ëŠ¥ í† ê¸€

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        # BGR -> RGB ë³€í™˜
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # **ì´ë¯¸ì§€ í–¥ìƒ ì ìš©**
        if enhancement_enabled:
            processed_image = enhance_image_for_detection(image_rgb)
        else:
            processed_image = image_rgb

        # **ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì–¼êµ´ ê°ì§€** (ë” ì‘ì€ ì–¼êµ´ë„ ê°ì§€)
        results = face_detection.process(processed_image)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ ë‹¤ìš´í•´ì„œë„ í•œë²ˆ ë” ì‹œë„ (ë©€ë¦¬ ìˆëŠ” ì‘ì€ ì–¼êµ´ ê°ì§€)
        if not results.detections:
            small_image = cv2.resize(processed_image, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
            results_small = face_detection.process(small_image)
            if results_small.detections:
                # ìŠ¤ì¼€ì¼ ë³´ì •
                for detection in results_small.detections:
                    # ì¢Œí‘œë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë³€í™˜
                    bboxC = detection.location_data.relative_bounding_box
                    bboxC.xmin /= 1.5
                    bboxC.ymin /= 1.5
                    bboxC.width /= 1.5
                    bboxC.height /= 1.5
                results = results_small

        # ìƒíƒœ í‘œì‹œ
        status_text = f"Enhancement: {'ON' if enhancement_enabled else 'OFF'} | Model: Long Range | Min Conf: 0.3"
        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

        # ì–¼êµ´ ê·¸ë¦¬ê¸°
        if results.detections:
            h, w, _ = frame.shape
            detection_count = len(results.detections)
            cv2.putText(frame, f"Faces Detected: {detection_count}", (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            for i, detection in enumerate(results.detections):
                bboxC = detection.location_data.relative_bounding_box
                x_min = int(bboxC.xmin * w)
                y_min = int(bboxC.ymin * h)
                box_width = int(bboxC.width * w)
                box_height = int(bboxC.height * h)

                # ì¸ì‹ ì‹ ë¢°ë„(%)
                score = detection.score[0]
                confidence_text = f"{int(score*100)}%"

                # ì–¼êµ´ í¬ê¸° ê³„ì‚° (ê±°ë¦¬ ì¶”ì •ìš©)
                face_area = box_width * box_height
                distance_estimate = "Near" if face_area > 20000 else "Medium" if face_area > 8000 else "Far"
                
                # ì–¼êµ´ ë²ˆí˜¸ ë° ê±°ë¦¬ ì •ë³´
                label = f"Person{i+1} ({confidence_text}) [{distance_estimate}]"

                # **ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€ê²½**
                if distance_estimate == "Far":
                    color = (0, 0, 255)    # ë¹¨ê°„ìƒ‰ (ë©€ë¦¬)
                elif distance_estimate == "Medium":
                    color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„)
                else:
                    color = (0, 255, 0)    # ì´ˆë¡ìƒ‰ (ê°€ê¹Œì´)

                thickness = max(3, int(current_scale * 4))
                cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height), 
                            color, thickness)

                # í…ìŠ¤íŠ¸ ì¶œë ¥
                font_scale = max(0.6, current_scale * 1.0)
                text_thickness = max(2, int(current_scale * 3))
                cv2.putText(frame, label, (x_min, y_min - 15),
                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, text_thickness)
                
                # ë°•ìŠ¤ ì¤‘ì•™ ì¢Œí‘œ ê³„ì‚°
                center_x = x_min + box_width // 2
                center_y = y_min + box_height // 2

                # ì¤‘ì•™ì  í‘œì‹œ (ê±°ë¦¬ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •)
                if distance_estimate == "Far":
                    circle_radius = max(3, int(current_scale * 5))
                elif distance_estimate == "Medium":
                    circle_radius = max(5, int(current_scale * 7))
                else:
                    circle_radius = max(7, int(current_scale * 9))
                    
                cv2.circle(frame, (center_x, center_y), circle_radius, (0, 0, 255), -1)

                # ì¢Œí‘œ ë° ë©´ì  í…ìŠ¤íŠ¸
                coord_font_scale = max(0.5, current_scale * 0.7)
                info_text = f"Center({center_x},{center_y}) Area:{face_area}"
                cv2.putText(frame, info_text,
                          (center_x + 20, center_y), 
                          cv2.FONT_HERSHEY_SIMPLEX, coord_font_scale, (0, 0, 255), text_thickness)
        else:
            # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ
            cv2.putText(frame, "No faces detected - Try moving closer or adjusting lighting", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        cv2.imshow(window_name, frame)

        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        key = cv2.waitKey(30) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('c'):
            timestamp = int(time.time())
            frame_filename = os.path.join(save_dir, f"enhanced_frame_{timestamp}.png")
            cv2.imwrite(frame_filename, frame)
            print(f"ğŸ“¸ í–¥ìƒëœ í”„ë ˆì„ ì €ì¥ ì™„ë£Œ: {frame_filename}")

            if results.detections:
                for i, detection in enumerate(results.detections):
                    bboxC = detection.location_data.relative_bounding_box
                    x_min = int(bboxC.xmin * w)
                    y_min = int(bboxC.ymin * h)
                    box_width = int(bboxC.width * w)
                    box_height = int(bboxC.height * h)

                    face_crop = frame[
                        max(0, y_min):min(h, y_min + box_height),
                        max(0, x_min):min(w, x_min + box_width)
                    ]

                    face_filename = os.path.join(save_dir, f"enhanced_face_{timestamp}_{i}.png")
                    cv2.imwrite(face_filename, face_crop)
                    print(f"ğŸ“¸ í–¥ìƒëœ ì–¼êµ´ {i} ì €ì¥ ì™„ë£Œ: {face_filename}")
                    
        elif key == ord('e'):  # ì´ë¯¸ì§€ í–¥ìƒ í† ê¸€
            enhancement_enabled = not enhancement_enabled
            print(f"ì´ë¯¸ì§€ í–¥ìƒ: {'í™œì„±í™”' if enhancement_enabled else 'ë¹„í™œì„±í™”'}")
            
        elif key == ord('+') or key == ord('='):
            current_scale = min(1.5, current_scale + 0.1)
            new_width = int(actual_width * current_scale)
            new_height = int(actual_height * current_scale)
            cv2.resizeWindow(window_name, new_width, new_height)
            print(f"ì°½ í¬ê¸° í™•ëŒ€: {new_width}x{new_height}")
            
        elif key == ord('-') or key == ord('_'):
            current_scale = max(0.3, current_scale - 0.1)
            new_width = int(actual_width * current_scale)
            new_height = int(actual_height * current_scale)
            cv2.resizeWindow(window_name, new_width, new_height)
            print(f"ì°½ í¬ê¸° ì¶•ì†Œ: {new_width}x{new_height}")
            
        elif key == ord('r'):
            current_scale = 0.8
            new_width = int(actual_width * current_scale)
            new_height = int(actual_height * current_scale)
            cv2.resizeWindow(window_name, new_width, new_height)
            print(f"ì°½ í¬ê¸° ë¦¬ì…‹: {new_width}x{new_height}")
            
        elif key == ord('f'):
            prop = cv2.getWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN)
            if prop == cv2.WINDOW_FULLSCREEN:
                cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
                print("ì „ì²´í™”ë©´ í•´ì œ")
            else:
                cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                print("ì „ì²´í™”ë©´ ëª¨ë“œ")

    cap.release()
    cv2.destroyAllWindows()
    print("í–¥ìƒëœ ì¥ê±°ë¦¬ ì–¼êµ´ ì¸ì‹ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
