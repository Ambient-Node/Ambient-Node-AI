import cv2
import mediapipe as mp
import time
import os
import numpy as np
import face_recognition
from PIL import ImageFont, ImageDraw, Image

# -----------------------
# ì„¤ì •
# -----------------------
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils

save_dir = "captures"
face_dir = "faces"
os.makedirs(save_dir, exist_ok=True)
os.makedirs(face_dir, exist_ok=True)

# í•œê¸€ í°íŠ¸ ê²½ë¡œ (macOS)
FONT_PATH = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

# -----------------------
# ì´ë¯¸ì§€ í–¥ìƒ í•¨ìˆ˜
# -----------------------
def enhance_image_for_detection(image):
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) 
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)
    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)
    return enhanced

# -----------------------
# í•œê¸€ í…ìŠ¤íŠ¸ ì¶œë ¥ í•¨ìˆ˜
# -----------------------
def put_text_kor(frame, text, pos, color=(0,255,0), font_size=30):
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    font = ImageFont.truetype(FONT_PATH, font_size)
    draw.text(pos, text, font=font, fill=color[::-1])
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# -----------------------
# ë“±ë¡ëœ ì–¼êµ´ ë¶ˆëŸ¬ì˜¤ê¸°
# -----------------------
def load_known_faces():
    known_encodings = []
    known_names = []
    for file in os.listdir(face_dir):
        path = os.path.join(face_dir, file)
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            img = face_recognition.load_image_file(path)
            enc = face_recognition.face_encodings(img)
            if enc:
                known_encodings.append(enc[0])
                known_names.append(os.path.splitext(file)[0])
    print(f"âœ… ë“±ë¡ëœ ì–¼êµ´ ìˆ˜: {len(known_names)} â†’ {known_names}")
    return known_encodings, known_names

known_encodings, known_names = load_known_faces()

# -----------------------
# ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹
# -----------------------
with mp_face_detection.FaceDetection(
    model_selection=1,
    min_detection_confidence=0.4) as face_detection:

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        for i in range(1,5):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                print(f"ì¹´ë©”ë¼ {i}ë²ˆ ì—°ê²° ì„±ê³µ")
                break
        else:
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì—†ìŒ")
        # exit() ëŒ€ì‹  while ë£¨í”„ì—ì„œ ê³„ì† ì‹œë„ ê°€ëŠ¥

    window_name = "Face Detection + Recognition"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)

    enhancement_enabled = True
    scale_factor = 0.8
    current_scale = scale_factor

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            continue

        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        processed_image = enhance_image_for_detection(image_rgb) if enhancement_enabled else image_rgb

        results = face_detection.process(processed_image)

        detected_faces = []
        if results.detections:
            h, w, _ = frame.shape
            for i, detection in enumerate(results.detections):
                bboxC = detection.location_data.relative_bounding_box
                x_min = int(bboxC.xmin * w)
                y_min = int(bboxC.ymin * h)
                box_width = int(bboxC.width * w)
                box_height = int(bboxC.height * h)

                face_crop = frame[
                    max(0, y_min):min(h, y_min + box_height),
                    max(0, x_min):min(w, x_min + box_width)
                ]
                detected_faces.append((x_min, y_min, box_width, box_height, face_crop))

                # ê¸°ë³¸ ì´ë¦„
                name = "Unknown"
                if face_crop.size > 0:
                    rgb_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
                    encodings = face_recognition.face_encodings(rgb_crop)
                    if encodings:
                        match = face_recognition.compare_faces(known_encodings, encodings[0], tolerance=0.45)
                        face_distances = face_recognition.face_distance(known_encodings, encodings[0])
                        best_match_index = np.argmin(face_distances) if len(face_distances) > 0 else None
                        if best_match_index is not None and match[best_match_index]:
                            name = known_names[best_match_index]

                # ì–¼êµ´ í¬ê¸° ê¸°ë°˜ ê±°ë¦¬ ì¶”ì •
                face_area = box_width * box_height
                distance_estimate = "Far" if face_area < 8000 else "Medium" if face_area < 20000 else "Near"

                # ë°•ìŠ¤ ìƒ‰ìƒ
                if distance_estimate == "Far":
                    color = (0, 0, 255)
                elif distance_estimate == "Medium":
                    color = (0, 165, 255)
                else:
                    color = (0, 255, 0)

                thickness = max(2, int(current_scale*3))
                cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height), color, thickness)

                # ì¤‘ì•™ì  í‘œì‹œ
                center_x = x_min + box_width // 2
                center_y = y_min + box_height // 2
                circle_radius = max(5, int(current_scale*7))
                cv2.circle(frame, (center_x, center_y), circle_radius, (0, 0, 255), -1)

                # ì‹ ë¢°ë„ í‘œì‹œ
                score = detection.score[0]
                confidence_text = f"{int(score*100)}%"
                label = f"{name} ({confidence_text}) [{distance_estimate}]"

                frame = put_text_kor(frame, label, (x_min, y_min - 25), color=color, font_size=int(20*current_scale))

                info_text = f"Center({center_x},{center_y}) Area:{face_area}"
                frame = put_text_kor(frame, info_text, (center_x + 20, center_y), color=(0,0,255), font_size=int(15*current_scale))

        # ìƒíƒœ í‘œì‹œ
        status_text = f"Enhancement: {'ON' if enhancement_enabled else 'OFF'} | Faces: {len(results.detections) if results.detections else 0}"
        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)

        cv2.imshow(window_name, frame)

        key = cv2.waitKey(30) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('c'):
            timestamp = int(time.time())
            cv2.imwrite(os.path.join(save_dir, f"frame_{timestamp}.png"), frame)
            print(f"ğŸ“¸ í”„ë ˆì„ ì €ì¥ ì™„ë£Œ: frame_{timestamp}.png")
        elif key == ord('e'):
            enhancement_enabled = not enhancement_enabled
            print(f"ì´ë¯¸ì§€ í–¥ìƒ: {'í™œì„±í™”' if enhancement_enabled else 'ë¹„í™œì„±í™”'}")
        elif key == ord('r'):
            if detected_faces:
                for i,(x,y,w_,h_,crop) in enumerate(detected_faces):
                    cv2.imshow(f"Register Face {i+1}", crop)

                    # ì‚¬ìš©ì ì„ íƒ: 1-ìƒˆ ë“±ë¡, 2-ì´ë¦„ ë³€ê²½, 3-ì·¨ì†Œ
                    action = input(f"Face {i+1}: 1-ë“±ë¡, 2-ì´ë¦„ ë³€ê²½, 3-ì·¨ì†Œ: ").strip()

                    if action == "1":  # ìƒˆ ì–¼êµ´ ë“±ë¡
                        new_name = input(f"ë“±ë¡í•  ì´ë¦„ (Face {i+1}): ").strip()
                        if new_name:
                            # -------------------------
                            # ì¤‘ë³µ ê²€ì‚¬ ë° ì‚­ì œ
                            # -------------------------
                            rgb_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
                            encodings = face_recognition.face_encodings(rgb_crop)
                            if encodings:
                                enc = encodings[0]
                                to_delete = []
                                for idx, known_enc in enumerate(known_encodings):
                                    dist = face_recognition.face_distance([known_enc], enc)[0]
                                    if dist < 0.4:  # ë™ì¼ ì¸ë¬¼
                                        print(f"âš ï¸ ê¸°ì¡´ ì–¼êµ´ '{known_names[idx]}' ì‚­ì œ í›„ ë“±ë¡")
                                        to_delete.append(known_names[idx])
                                for name_del in to_delete:
                                    path_del = os.path.join(face_dir, f"{name_del}.jpg")
                                    if os.path.exists(path_del):
                                        os.remove(path_del)
                                        print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {path_del}")

                            # -------------------------
                            # ìƒˆë¡œìš´ ì–¼êµ´ ì €ì¥
                            # -------------------------
                            filename = os.path.join(face_dir, f"{new_name}.jpg")
                            cv2.imwrite(filename, crop)
                            print(f"âœ… ì–¼êµ´ ë“±ë¡ ì™„ë£Œ: {filename}")

                    elif action == "2":  # ì´ë¦„ ë³€ê²½
                        rgb_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
                        encodings = face_recognition.face_encodings(rgb_crop)
                        if encodings:
                            enc = encodings[0]
                            # ê°€ì¥ ê°€ê¹Œìš´ ê¸°ì¡´ ì–¼êµ´ ì°¾ê¸°
                            distances = face_recognition.face_distance(known_encodings, enc)
                            if len(distances) > 0:
                                idx = np.argmin(distances)
                                old_name = known_names[idx]
                                new_name = input(f"'{old_name}'ì˜ ìƒˆ ì´ë¦„: ").strip()
                                if new_name:
                                    old_path = os.path.join(face_dir, f"{old_name}.jpg")
                                    new_path = os.path.join(face_dir, f"{new_name}.jpg")
                                    if os.path.exists(old_path):
                                        os.rename(old_path, new_path)
                                        print(f"ğŸ”„ '{old_name}' â†’ '{new_name}' ë³€ê²½ ì™„ë£Œ")
                                        # ë°•ìŠ¤ì— í‘œì‹œë˜ëŠ” ì´ë¦„ ê°±ì‹ 
                                        known_encodings, known_names = load_known_faces()

                    else:  # ì·¨ì†Œ
                        print("ë“±ë¡/ì´ë¦„ ë³€ê²½ ì·¨ì†Œ")

                # ë“±ë¡/ë³€ê²½ í›„ ì¸ì½”ë”© ì¬ë¡œë“œ
                known_encodings, known_names = load_known_faces()


    cap.release()
    cv2.destroyAllWindows()
    print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
